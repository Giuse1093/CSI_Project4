{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOzGhRKH/stvsgv45sVXhv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Giuse1093/CSI_Project4/blob/main/data_processing5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uGiuwQk02MUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e8a9b6-700b-4ea7-cc60-82be02c43b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decompressione CSV_train.zip...\n",
            "Fatto!\n"
          ]
        }
      ],
      "source": [
        "# --- CELLA 1: INSTALLAZIONE E SETUP ---\n",
        "!pip install -q flwr pandas numpy scipy scikit-learn\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.fft import fft\n",
        "from scipy.stats import skew, kurtosis, linregress, entropy\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Decompressione Dataset\n",
        "if not os.path.exists(\"CSV_train\") and os.path.exists(\"CSV_train.zip\"):\n",
        "    print(\"Decompressione CSV_train.zip...\")\n",
        "    with zipfile.ZipFile(\"CSV_train.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"CSV_train\")\n",
        "    print(\"Fatto!\")\n",
        "elif not os.path.exists(\"CSV_train.zip\"):\n",
        "    print(\"‚ö†Ô∏è ATTENZIONE: Carica il file 'CSV_train.zip' e 'x_test.csv' su Colab!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELLA 2: PREPROCESSING MEDICAL GRADE ---\n",
        "\n",
        "TS_COLS = ['hr_time_series', 'resp_time_series', 'stress_time_series', 'activity_time_series']\n",
        "\n",
        "def clean_series_interpolation(series_str):\n",
        "    if not isinstance(series_str, str):\n",
        "        return np.array([])\n",
        "    try:\n",
        "        data = np.array(ast.literal_eval(series_str), dtype=float)\n",
        "        data[data <= 0] = np.nan\n",
        "        if np.all(np.isnan(data)):\n",
        "            return np.array([0.0])\n",
        "        s_data = pd.Series(data)\n",
        "        s_data = s_data.interpolate(method='linear', limit_direction='both')\n",
        "        s_data = s_data.fillna(0)\n",
        "        return s_data.values\n",
        "    except:\n",
        "        return np.array([0.0])\n",
        "\n",
        "def calculate_params(matrix):\n",
        "    \"\"\"\n",
        "    Estrae feature avanzate + metriche fisiologiche (HRV proxy).\n",
        "    Restituisce 14 feature totali.\n",
        "    \"\"\"\n",
        "    if len(matrix) <= 1:\n",
        "        # CORREZIONE: Ora sono 14 feature, non 13\n",
        "        return [0.0] * 14\n",
        "\n",
        "    # 1. Statistiche Base\n",
        "    mean = np.mean(matrix)\n",
        "    std = np.std(matrix)\n",
        "    min_val = np.min(matrix)\n",
        "    max_val = np.max(matrix)\n",
        "\n",
        "    # 2. Percentili\n",
        "    p25 = np.percentile(matrix, 25)\n",
        "    p50 = np.percentile(matrix, 50)\n",
        "    p75 = np.percentile(matrix, 75)\n",
        "\n",
        "    # 3. Forma e Trend\n",
        "    sk = skew(matrix) if std > 0 else 0\n",
        "    ku = kurtosis(matrix) if std > 0 else 0\n",
        "\n",
        "    try:\n",
        "        slope, _, _, _, _ = linregress(np.arange(len(matrix)), matrix)\n",
        "        if np.isnan(slope): slope = 0.0\n",
        "    except:\n",
        "        slope = 0.0\n",
        "\n",
        "    # 4. Energia Spettrale\n",
        "    f_trans = fft(matrix)\n",
        "    energy = np.sum(np.abs(f_trans)**2) / len(matrix)\n",
        "\n",
        "    # --- NUOVE FEATURE AGGIUNTE ---\n",
        "\n",
        "    # 5. RMSSD Proxy (Root Mean Square of Successive Differences)\n",
        "    diff = np.diff(matrix)\n",
        "    rmssd = np.sqrt(np.mean(diff**2)) if len(diff) > 0 else 0\n",
        "\n",
        "    # 6. Zero Crossings (Rispetto alla media)\n",
        "    zero_crossings = np.where(np.diff(np.sign(matrix - mean)))[0].size\n",
        "\n",
        "    # 7. Entropia di Shannon\n",
        "    counts, _ = np.histogram(matrix, bins=10, density=True)\n",
        "    ent = entropy(counts + 1e-10)\n",
        "\n",
        "    # Totale 14 feature\n",
        "    return [mean, std, min_val, max_val, p25, p50, p75, sk, ku, slope, energy, rmssd, zero_crossings, ent]\n",
        "\n",
        "def process_dataframe(df):\n",
        "    extracted_data = []\n",
        "    # Escludiamo le colonne non scalari e label/id/date\n",
        "    scalar_cols = [c for c in df.columns if 'time_series' not in c and c != 'label' and c != 'id' and 'date' not in c]\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        row_features = []\n",
        "        # Feature Scalari esistenti\n",
        "        for col in scalar_cols:\n",
        "            val = row[col] if pd.notnull(row[col]) else 0.0\n",
        "            row_features.append(val)\n",
        "\n",
        "        # Feature Time Series\n",
        "        for col in TS_COLS:\n",
        "            if col in df.columns:\n",
        "                clean_seq = clean_series_interpolation(row[col])\n",
        "                feats = calculate_params(clean_seq)\n",
        "                row_features.extend(feats)\n",
        "\n",
        "        extracted_data.append(row_features)\n",
        "\n",
        "    col_names = list(scalar_cols)\n",
        "    suffixes = ['mean', 'std', 'min', 'max', 'p25', 'p50', 'p75', 'skew', 'kurt', 'slope', 'energy', 'rmssd', 'zcross', 'entropy']\n",
        "    for ts_col in TS_COLS:\n",
        "        if ts_col in df.columns:\n",
        "            base_name = ts_col.replace('_time_series', '')\n",
        "            for s in suffixes:\n",
        "                col_names.append(f\"{base_name}_{s}\")\n",
        "\n",
        "    return pd.DataFrame(extracted_data, columns=col_names)\n",
        "\n",
        "print(\"Preprocessing Medical Grade pronto.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IktUx0d2n3l",
        "outputId": "730cae86-a8bb-48d5-d011-f0b9305cf8d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing Medical Grade pronto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELLA 3: TRAINING FEDERATO \"SMART\" (Quality Gating) ---\n",
        "\n",
        "def run_federated_simulation_smart():\n",
        "    TRAIN_ROOT = \"CSV_train\"\n",
        "    global_estimators = []\n",
        "\n",
        "    all_val_features = []\n",
        "    all_val_labels = []\n",
        "\n",
        "    client_folders = []\n",
        "    for root, dirs, files in os.walk(TRAIN_ROOT):\n",
        "        csv_files = [f for f in files if f.endswith('.csv')]\n",
        "        if csv_files:\n",
        "            client_folders.append(root)\n",
        "\n",
        "    print(f\"Training Federato Smart su {len(client_folders)} client...\")\n",
        "\n",
        "    # Variabili per inizializzazione modello globale\n",
        "    first_X_train = None\n",
        "    first_y_train = None\n",
        "\n",
        "    accepted_clients = 0\n",
        "    rejected_clients = 0\n",
        "\n",
        "    for i, folder in enumerate(client_folders):\n",
        "        files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv')]\n",
        "        df_list = [pd.read_csv(f, sep=';') for f in files]\n",
        "        if not df_list: continue\n",
        "\n",
        "        df_client = pd.concat(df_list, ignore_index=True)\n",
        "        if 'label' not in df_client.columns: continue\n",
        "\n",
        "        y = df_client['label'].values\n",
        "        X = process_dataframe(df_client)\n",
        "\n",
        "        # Saltiamo client con troppi pochi dati\n",
        "        if len(X) < 10: continue\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Salviamo il primo per inizializzare il global container\n",
        "        if first_X_train is None:\n",
        "            first_X_train = X_train\n",
        "            first_y_train = y_train\n",
        "\n",
        "        # Salviamo i dati di validazione per il test finale globale\n",
        "        all_val_features.append(X_val)\n",
        "        all_val_labels.append(y_val)\n",
        "\n",
        "        # 3. Training Locale (Pi√π aggressivo ora)\n",
        "        clf = RandomForestRegressor(\n",
        "            n_estimators=60,       # Aumentato: pi√π alberi per client\n",
        "            max_depth=20,          # Aumentato: cattura relazioni pi√π complesse\n",
        "            min_samples_leaf=2,\n",
        "            max_features='sqrt',   # Evita overfitting\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # --- QUALITY GATE ---\n",
        "        # Il client valuta se stesso prima di inviare\n",
        "        local_pred = clf.predict(X_val)\n",
        "        local_mae = mean_absolute_error(y_val, local_pred)\n",
        "\n",
        "        # Se il MAE locale √® > 18 (modello confuso), scartiamo il contributo\n",
        "        if local_mae < 18.0:\n",
        "            global_estimators.extend(clf.estimators_)\n",
        "            accepted_clients += 1\n",
        "        else:\n",
        "            rejected_clients += 1\n",
        "            # (Opzionale) Print per debug\n",
        "            # print(f\"Client {i} scartato (MAE Locale: {local_mae:.2f})\")\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f\"   ...processati {i+1} client (Accettati: {accepted_clients}, Scartati: {rejected_clients})\")\n",
        "\n",
        "    print(f\"\\nTraining concluso. Contributi integrati: {accepted_clients}/{len(client_folders)}\")\n",
        "    print(\"Assemblaggio Modello Globale...\")\n",
        "\n",
        "    # 1. Container vuoto\n",
        "    dummy_model = RandomForestRegressor(n_estimators=len(global_estimators), random_state=42, n_jobs=-1)\n",
        "    # 2. Inizializzazione struttura\n",
        "    dummy_model.fit(first_X_train, first_y_train)\n",
        "    # 3. Iniezione intelligenza federata\n",
        "    dummy_model.estimators_ = global_estimators\n",
        "\n",
        "    print(\"\\n--- VALUTAZIONE GLOBALE ---\")\n",
        "\n",
        "    X_global_val = pd.concat(all_val_features, ignore_index=True)\n",
        "    y_global_true = np.concatenate(all_val_labels)\n",
        "\n",
        "    raw_preds = dummy_model.predict(X_global_val)\n",
        "\n",
        "    preds_clipped = np.clip(raw_preds, 0, 100)\n",
        "    preds_integer = np.rint(preds_clipped).astype(int)\n",
        "\n",
        "    mae = mean_absolute_error(y_global_true, preds_integer)\n",
        "\n",
        "    print(f\"Campioni testati: {len(y_global_true)}\")\n",
        "    print(f\"Errore Medio Assoluto (MAE) REALE: {mae:.4f}\")\n",
        "\n",
        "    if mae < 11.5:\n",
        "        print(\"\\nüöÄ OTTIMO! Stiamo scendendo verso il target.\")\n",
        "    elif mae < 12.5:\n",
        "        print(\"\\n‚úÖ Miglioramento stabile.\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Stabile.\")\n",
        "\n",
        "    return dummy_model\n",
        "\n",
        "# ESECUZIONE\n",
        "global_model = run_federated_simulation_smart()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xtqdBye2uDw",
        "outputId": "b578ae9a-8bd4-4e5f-e23e-45bf90312094"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Federato Smart su 9 client...\n",
            "\n",
            "Training concluso. Contributi integrati: 9/9\n",
            "Assemblaggio Modello Globale...\n",
            "\n",
            "--- VALUTAZIONE GLOBALE ---\n",
            "Campioni testati: 204\n",
            "Errore Medio Assoluto (MAE) REALE: 11.4118\n",
            "\n",
            "üöÄ OTTIMO! Stiamo scendendo verso il target.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELLA 4: SUBMISSION FINALE ---\n",
        "if os.path.exists(\"x_test.csv\"):\n",
        "    print(\"\\nGenerazione file submission...\")\n",
        "    df_test = pd.read_csv(\"x_test.csv\", sep=';')\n",
        "\n",
        "    # 1. Preprocessing\n",
        "    X_test = process_dataframe(df_test)\n",
        "\n",
        "    # 2. Allineamento Colonne (Fix per feature mancanti/extra)\n",
        "    trained_features = global_model.feature_names_in_\n",
        "    # Aggiungi mancanti\n",
        "    for c in trained_features:\n",
        "        if c not in X_test.columns: X_test[c] = 0.0\n",
        "    # Rimuovi extra e riordina\n",
        "    X_test = X_test[trained_features]\n",
        "\n",
        "    # 3. Predizione e Arrotondamento\n",
        "    raw_preds = global_model.predict(X_test)\n",
        "\n",
        "    # STESSA LOGICA DELLA CELLA 3\n",
        "    preds_clipped = np.clip(raw_preds, 0, 100)\n",
        "    preds_int = np.rint(preds_clipped).astype(int)\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        'id': df_test['id'],\n",
        "        'label': preds_int\n",
        "    })\n",
        "\n",
        "    submission.to_csv('submission_int.csv', index=False)\n",
        "    print(\"‚úÖ File 'submission_int.csv' pronto! (Valori interi 0-100)\")\n",
        "    print(submission.head())\n",
        "else:\n",
        "    print(\"‚ùå Manca x_test.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J44NCADP2xsT",
        "outputId": "016b6e28-b60e-4267-b626-f82e4325fa5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generazione file submission...\n",
            "‚úÖ File 'submission_int.csv' pronto! (Valori interi 0-100)\n",
            "   id  label\n",
            "0   0     68\n",
            "1   1     69\n",
            "2   2     70\n",
            "3   3     69\n",
            "4   4     75\n"
          ]
        }
      ]
    }
  ]
}