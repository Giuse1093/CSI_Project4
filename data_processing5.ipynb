{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHf0AVnGhtHou7u0czMk+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Giuse1093/CSI_Project4/blob/main/data_processing5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGiuwQk02MUs"
      },
      "outputs": [],
      "source": [
        "# --- CELLA 1: INSTALLAZIONE E SETUP ---\n",
        "!pip install -q flwr pandas numpy scipy scikit-learn\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.fft import fft\n",
        "from scipy.stats import skew, kurtosis, linregress, entropy\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Decompressione Dataset\n",
        "if not os.path.exists(\"CSV_train\") and os.path.exists(\"CSV_train.zip\"):\n",
        "    print(\"Decompressione CSV_train.zip...\")\n",
        "    with zipfile.ZipFile(\"CSV_train.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"CSV_train\")\n",
        "    print(\"Fatto!\")\n",
        "elif not os.path.exists(\"CSV_train.zip\"):\n",
        "    print(\"⚠️ ATTENZIONE: Carica il file 'CSV_train.zip' e 'x_test.csv' su Colab!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELLA 2: PREPROCESSING MEDICAL GRADE ---\n",
        "\n",
        "TS_COLS = ['hr_time_series', 'resp_time_series', 'stress_time_series', 'activity_time_series']\n",
        "\n",
        "def clean_series_interpolation(series_str):\n",
        "    if not isinstance(series_str, str):\n",
        "        return np.array([])\n",
        "    try:\n",
        "        data = np.array(ast.literal_eval(series_str), dtype=float)\n",
        "        data[data <= 0] = np.nan\n",
        "        if np.all(np.isnan(data)):\n",
        "            return np.array([0.0])\n",
        "        s_data = pd.Series(data)\n",
        "        s_data = s_data.interpolate(method='linear', limit_direction='both')\n",
        "        s_data = s_data.fillna(0)\n",
        "        return s_data.values\n",
        "    except:\n",
        "        return np.array([0.0])\n",
        "\n",
        "def calculate_params(matrix):\n",
        "    \"\"\"\n",
        "    Estrae feature avanzate + metriche fisiologiche (HRV proxy).\n",
        "    Restituisce 14 feature totali.\n",
        "    \"\"\"\n",
        "    if len(matrix) <= 1:\n",
        "        # CORREZIONE: Ora sono 14 feature, non 13\n",
        "        return [0.0] * 14\n",
        "\n",
        "    # 1. Statistiche Base\n",
        "    mean = np.mean(matrix)\n",
        "    std = np.std(matrix)\n",
        "    min_val = np.min(matrix)\n",
        "    max_val = np.max(matrix)\n",
        "\n",
        "    # 2. Percentili\n",
        "    p25 = np.percentile(matrix, 25)\n",
        "    p50 = np.percentile(matrix, 50)\n",
        "    p75 = np.percentile(matrix, 75)\n",
        "\n",
        "    # 3. Forma e Trend\n",
        "    sk = skew(matrix) if std > 0 else 0\n",
        "    ku = kurtosis(matrix) if std > 0 else 0\n",
        "\n",
        "    try:\n",
        "        slope, _, _, _, _ = linregress(np.arange(len(matrix)), matrix)\n",
        "        if np.isnan(slope): slope = 0.0\n",
        "    except:\n",
        "        slope = 0.0\n",
        "\n",
        "    # 4. Energia Spettrale\n",
        "    f_trans = fft(matrix)\n",
        "    energy = np.sum(np.abs(f_trans)**2) / len(matrix)\n",
        "\n",
        "    # --- NUOVE FEATURE AGGIUNTE ---\n",
        "\n",
        "    # 5. RMSSD Proxy (Root Mean Square of Successive Differences)\n",
        "    diff = np.diff(matrix)\n",
        "    rmssd = np.sqrt(np.mean(diff**2)) if len(diff) > 0 else 0\n",
        "\n",
        "    # 6. Zero Crossings (Rispetto alla media)\n",
        "    zero_crossings = np.where(np.diff(np.sign(matrix - mean)))[0].size\n",
        "\n",
        "    # 7. Entropia di Shannon\n",
        "    counts, _ = np.histogram(matrix, bins=10, density=True)\n",
        "    ent = entropy(counts + 1e-10)\n",
        "\n",
        "    # Totale 14 feature\n",
        "    return [mean, std, min_val, max_val, p25, p50, p75, sk, ku, slope, energy, rmssd, zero_crossings, ent]\n",
        "\n",
        "def process_dataframe(df):\n",
        "    extracted_data = []\n",
        "    # Escludiamo le colonne non scalari e label/id/date\n",
        "    scalar_cols = [c for c in df.columns if 'time_series' not in c and c != 'label' and c != 'id' and 'date' not in c]\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        row_features = []\n",
        "        # Feature Scalari esistenti\n",
        "        for col in scalar_cols:\n",
        "            val = row[col] if pd.notnull(row[col]) else 0.0\n",
        "            row_features.append(val)\n",
        "\n",
        "        # Feature Time Series\n",
        "        for col in TS_COLS:\n",
        "            if col in df.columns:\n",
        "                clean_seq = clean_series_interpolation(row[col])\n",
        "                feats = calculate_params(clean_seq)\n",
        "                row_features.extend(feats)\n",
        "\n",
        "        extracted_data.append(row_features)\n",
        "\n",
        "    col_names = list(scalar_cols)\n",
        "    suffixes = ['mean', 'std', 'min', 'max', 'p25', 'p50', 'p75', 'skew', 'kurt', 'slope', 'energy', 'rmssd', 'zcross', 'entropy']\n",
        "    for ts_col in TS_COLS:\n",
        "        if ts_col in df.columns:\n",
        "            base_name = ts_col.replace('_time_series', '')\n",
        "            for s in suffixes:\n",
        "                col_names.append(f\"{base_name}_{s}\")\n",
        "\n",
        "    return pd.DataFrame(extracted_data, columns=col_names)\n",
        "\n",
        "print(\"Preprocessing Medical Grade pronto.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IktUx0d2n3l",
        "outputId": "18a83b58-2940-4e02-9b37-194569f9fbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing Medical Grade pronto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELLA 3: TRAINING FEDERATO AGGRESSIVO ---\n",
        "\n",
        "def run_federated_simulation_with_score():\n",
        "    TRAIN_ROOT = \"CSV_train\"\n",
        "    global_estimators = []\n",
        "\n",
        "    all_val_features = []\n",
        "    all_val_labels = []\n",
        "\n",
        "    client_folders = []\n",
        "    for root, dirs, files in os.walk(TRAIN_ROOT):\n",
        "        csv_files = [f for f in files if f.endswith('.csv')]\n",
        "        if csv_files:\n",
        "            client_folders.append(root)\n",
        "\n",
        "    print(f\"Training Federato su {len(client_folders)} client...\")\n",
        "\n",
        "    # Variabili per inizializzazione modello globale\n",
        "    first_X_train = None\n",
        "    first_y_train = None\n",
        "\n",
        "    for i, folder in enumerate(client_folders):\n",
        "        files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv')]\n",
        "        df_list = [pd.read_csv(f, sep=';') for f in files]\n",
        "        if not df_list: continue\n",
        "\n",
        "        df_client = pd.concat(df_list, ignore_index=True)\n",
        "        if 'label' not in df_client.columns: continue\n",
        "\n",
        "        y = df_client['label'].values\n",
        "        X = process_dataframe(df_client)\n",
        "\n",
        "        if len(X) < 5: continue\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Salviamo un campione per inizializzare il modello globale alla fine\n",
        "        if first_X_train is None:\n",
        "            first_X_train = X_train\n",
        "            first_y_train = y_train\n",
        "\n",
        "        all_val_features.append(X_val)\n",
        "        all_val_labels.append(y_val)\n",
        "\n",
        "        # 3. Training Locale\n",
        "        clf = RandomForestRegressor(\n",
        "            n_estimators=40,\n",
        "            max_depth=15,\n",
        "            min_samples_leaf=2,\n",
        "            max_features='sqrt',\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        clf.fit(X_train, y_train)\n",
        "        global_estimators.extend(clf.estimators_)\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f\"   ...completati {i+1} client.\")\n",
        "\n",
        "    print(\"\\nAssemblaggio Modello Globale...\")\n",
        "    # CORREZIONE CRITICA:\n",
        "    # 1. Creiamo il contenitore\n",
        "    dummy_model = RandomForestRegressor(n_estimators=len(global_estimators), random_state=42, n_jobs=-1)\n",
        "    # 2. Facciamo fit su un dataset fittizio (il primo client) SOLO per inizializzare le classi interne\n",
        "    dummy_model.fit(first_X_train, first_y_train)\n",
        "    # 3. SOVRASCRIVIAMO gli alberi con quelli federati (ora non vengono più cancellati)\n",
        "    dummy_model.estimators_ = global_estimators\n",
        "\n",
        "    print(\"\\n--- VALUTAZIONE PRECISA (LEADERBOARD SIMULATA) ---\")\n",
        "\n",
        "    X_global_val = pd.concat(all_val_features, ignore_index=True)\n",
        "    y_global_true = np.concatenate(all_val_labels)\n",
        "\n",
        "    # Predizione\n",
        "    raw_preds = dummy_model.predict(X_global_val)\n",
        "\n",
        "    # Arrotondamento Intero\n",
        "    preds_clipped = np.clip(raw_preds, 0, 100)\n",
        "    preds_integer = np.rint(preds_clipped).astype(int)\n",
        "\n",
        "    mae = mean_absolute_error(y_global_true, preds_integer)\n",
        "\n",
        "    print(f\"Campioni testati: {len(y_global_true)}\")\n",
        "    print(f\"Errore Medio Assoluto (MAE) REALE: {mae:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Esempi ---\")\n",
        "    results = pd.DataFrame({\n",
        "        'Vero': y_global_true[:8],\n",
        "        'Pred_Int': preds_integer[:8],\n",
        "        'Delta': np.abs(y_global_true[:8] - preds_integer[:8])\n",
        "    })\n",
        "    print(results)\n",
        "\n",
        "    if mae < 11:\n",
        "        print(\"\\n✅ SEI IN ZONA VITTORIA! Invia subito.\")\n",
        "    elif mae < 13:\n",
        "        print(\"\\n⚠️ BUONO. Ma si può migliorare.\")\n",
        "    else:\n",
        "        print(\"\\n❌ ANCORA ALTO.\")\n",
        "\n",
        "    return dummy_model\n",
        "\n",
        "# ESECUZIONE\n",
        "global_model = run_federated_simulation_with_score()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xtqdBye2uDw",
        "outputId": "59a9c57d-2f3b-40e2-864c-f33c3a486891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Federato su 9 client...\n",
            "   ...completati 5 client.\n",
            "\n",
            "Assemblaggio Modello Globale...\n",
            "\n",
            "--- VALUTAZIONE PRECISA (LEADERBOARD SIMULATA) ---\n",
            "Campioni testati: 204\n",
            "Errore Medio Assoluto (MAE) REALE: 11.9069\n",
            "\n",
            "--- Esempi ---\n",
            "   Vero  Pred_Int  Delta\n",
            "0    90        72     18\n",
            "1    78        78      0\n",
            "2    86        74     12\n",
            "3    87        69     18\n",
            "4    92        76     16\n",
            "5    77        77      0\n",
            "6    84        76      8\n",
            "7    92        69     23\n",
            "\n",
            "⚠️ BUONO. Ma si può migliorare.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELLA 4: SUBMISSION FINALE ---\n",
        "if os.path.exists(\"x_test.csv\"):\n",
        "    print(\"\\nGenerazione file submission...\")\n",
        "    df_test = pd.read_csv(\"x_test.csv\", sep=';')\n",
        "\n",
        "    # 1. Preprocessing\n",
        "    X_test = process_dataframe(df_test)\n",
        "\n",
        "    # 2. Allineamento Colonne (Fix per feature mancanti/extra)\n",
        "    trained_features = global_model.feature_names_in_\n",
        "    # Aggiungi mancanti\n",
        "    for c in trained_features:\n",
        "        if c not in X_test.columns: X_test[c] = 0.0\n",
        "    # Rimuovi extra e riordina\n",
        "    X_test = X_test[trained_features]\n",
        "\n",
        "    # 3. Predizione e Arrotondamento\n",
        "    raw_preds = global_model.predict(X_test)\n",
        "\n",
        "    # STESSA LOGICA DELLA CELLA 3\n",
        "    preds_clipped = np.clip(raw_preds, 0, 100)\n",
        "    preds_int = np.rint(preds_clipped).astype(int)\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        'id': df_test['id'],\n",
        "        'label': preds_int\n",
        "    })\n",
        "\n",
        "    submission.to_csv('submission_int.csv', index=False)\n",
        "    print(\"✅ File 'submission_int.csv' pronto! (Valori interi 0-100)\")\n",
        "    print(submission.head())\n",
        "else:\n",
        "    print(\"❌ Manca x_test.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J44NCADP2xsT",
        "outputId": "96bbb2f5-9180-478c-fae5-92289918372e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generazione file submission...\n",
            "✅ File 'submission_int.csv' pronto! (Valori interi 0-100)\n",
            "   id  label\n",
            "0   0     69\n",
            "1   1     71\n",
            "2   2     71\n",
            "3   3     69\n",
            "4   4     75\n"
          ]
        }
      ]
    }
  ]
}